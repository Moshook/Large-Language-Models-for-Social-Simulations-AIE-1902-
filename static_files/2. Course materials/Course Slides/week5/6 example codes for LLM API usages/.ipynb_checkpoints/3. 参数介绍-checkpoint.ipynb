{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数设置\n",
    "- model:模型选择。\n",
    "    - gpt-4o-mini\n",
    "    - gpt-4o\n",
    "- messages:\n",
    "    - role\n",
    "        - system\n",
    "        - user\n",
    "        - assistant\n",
    "    - content\n",
    "- temperature:范围在0到2之间，默认为1。应该使用什么样的采样温度？较高的值（如0.8）会使输出更随机，而较低的值（如0.2）则会使其更加集中和确定性。\n",
    "- n:每次产生多少条回复，默认为1。\n",
    "- stream:是否连续输出，默认为False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # 这里换成你的密钥\n",
    "    api_key=\"fk204054-M7aFv2t5pdWOSBMTURsUClih3sPHb8qQ|ck872-e5b3a2d\",\n",
    "    # 这里将官方的接口访问地址，替换成api2d的入口地址\n",
    "    base_url=\"https://openai.api2d.net/v1\"\n",
    ")\n",
    "\n",
    "def get_completion(prompt, stream=False, model=\"gpt-4o-mini\", temperature=1):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        messages = messages,\n",
    "        model = model,\n",
    "        stream = stream,\n",
    "        temperature = temperature,\n",
    "    )\n",
    "    # 如果是连续输出模式\n",
    "    if stream==True:\n",
    "        # 返回一个生成器\n",
    "        return response\n",
    "    else:\n",
    "        # 一次性输出模式\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定制客户邮件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将根据客户评价和情感撰写自定义电子邮件响应。因此，我们将给定客户评价和情感，并生成自定义响应即使用 LLM 根据客户评价和评论情感生成定制电子邮件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先给出一个示例，包括一个评论及对应的情感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们可以在推理那章学习到如何对一个评论判断其情感倾向\n",
    "sentiment = \"negative\"\n",
    "\n",
    "# 一个产品的评价\n",
    "review = f\"\"\"\n",
    "他们在11月份的季节性销售期间以约49美元的价格出售17件套装，折扣约为一半。\\\n",
    "但由于某些原因（可能是价格欺诈），到了12月第二周，同样的套装价格全都涨到了70美元到89美元不等。\\\n",
    "11件套装的价格也上涨了大约10美元左右。\\\n",
    "虽然外观看起来还可以，但基座上锁定刀片的部分看起来不如几年前的早期版本那么好。\\\n",
    "不过我打算非常温柔地使用它，例如，\\\n",
    "我会先在搅拌机中将像豆子、冰、米饭等硬物研磨，然后再制成所需的份量，\\\n",
    "切换到打蛋器制作更细的面粉，或者在制作冰沙时先使用交叉切割刀片，然后使用平面刀片制作更细/不粘的效果。\\\n",
    "制作冰沙时，特别提示：\\\n",
    "将水果和蔬菜切碎并冷冻（如果使用菠菜，则轻轻煮软菠菜，然后冷冻直到使用；\\\n",
    "如果制作果酱，则使用小到中号的食品处理器），这样可以避免在制作冰沙时添加太多冰块。\\\n",
    "大约一年后，电机发出奇怪的噪音，我打电话给客服，但保修已经过期了，所以我不得不再买一个。\\\n",
    "总的来说，这些产品的总体质量已经下降，因此它们依靠品牌认可和消费者忠诚度来维持销售。\\\n",
    "货物在两天内到达。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经使用推断课程中学到的提取了情感，这是一个关于搅拌机的客户评价，现在我们将根据情感定制回复。\n",
    "\n",
    "这里的指令是：假设你是一个客户服务AI助手，你的任务是为客户发送电子邮件回复，根据通过三个反引号分隔的客户电子邮件，生成一封回复以感谢客户的评价。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用温度系数\n",
    "\n",
    "接下来，我们将使用语言模型的一个称为“温度”的参数，它将允许我们改变模型响应的多样性。我们可以将温度视为模型探索或随机性的程度。  \n",
    "一般来说，在构建比较固定的回答时，我们可以使用温度为0。如果需要构建一个可靠和可预测的系统，我们应该选择温度0。如果需要更具创意的方式使用模型，需要更广泛地输出不同的结果，那么可能需要使用更高的温度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尊敬的客户，\n",
      "\n",
      "非常感谢您详细描述您对我们产品的体验。我们深表歉意，产品在使用过程中给您带来了一些不便和困扰。我们会认真对待您提出的问题，并将努力改进产品质量，以提供更好的用户体验。\n",
      "\n",
      "同时，我们也感谢您对我们品牌的认可和忠诚。客户的反馈对我们非常重要，我们将会认真对待，并持续改进产品和服务，以满足客户的需求。\n",
      "\n",
      "如果您有任何其他问题或建议，请随时与我们联系。再次感谢您选择我们的产品。\n",
      "\n",
      "祝您生活愉快！\n",
      "\n",
      "AI客户代理\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "你是一位客户服务的AI助手。\n",
    "你的任务是给一位重要客户发送邮件回复。\n",
    "根据客户通过“```”分隔的评价，生成回复以感谢客户的评价。提醒模型使用评价中的具体细节\n",
    "用简明而专业的语气写信。\n",
    "作为“AI客户代理”签署电子邮件。\n",
    "客户评论：\n",
    "```{review}```\n",
    "评论情感：{sentiment}\n",
    "\"\"\"\n",
    "response = get_completion(prompt, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "尊敬的客户，\n",
    "\n",
    "非常感谢您分享您的宝贵意见和反馈。我们对您在购买过程中遇到的问题感到抱歉，我们将认真对待您提出的问题，并努力改进产品质量和服务水平。\n",
    "\n",
    "您提到的关于产品价格上涨和质量下降的问题，我们会将这些问题反馈给相关部门，并积极采取措施进行改进。同时，我们也会加强对产品的质量控制，确保产品能够达到客户的期望标准。\n",
    "\n",
    "如果您在未来有任何疑问或需要帮助，请随时与我们联系。我们将竭诚为您提供支持和帮助。\n",
    "\n",
    "再次感谢您对我们的支持和反馈。\n",
    "\n",
    "祝您生活愉快！\n",
    "\n",
    "AI客户代理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "尊敬的客户，\n",
    "\n",
    "非常感谢您对我们产品的详细评价。我们对您在使用过程中遇到的问题感到抱歉，我们将会认真考虑您提出的问题，并努力改进产品质量和服务水平。同时，我们也感谢您对我们品牌的认可和忠诚度。\n",
    "\n",
    "如果您有任何其他问题或需要进一步帮助，请随时与我们联系。期待能够为您提供更好的产品和服务。\n",
    "\n",
    "祝您生活愉快！\n",
    "\n",
    "AI客户代理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
